# ğŸ® Gaming Data Warehouse Project - README

## ğŸ“š Project Overview

This project implements a **Gaming Data Warehouse** to analyze player engagement, game sessions, and in-game purchases. The ETL pipeline automates data extraction, transformation, and loading into **Google BigQuery** using **Windows Task Scheduler**.

## ğŸ“‘ Table of Contents

1. [ğŸ“ Project Structure](#project-structure)
2. [âš™ï¸ Setup Instructions](#setup-instructions)
3. [â° ETL Automation with Task Scheduler](#etl-automation-with-task-scheduler)
4. [ğŸš€ Running the ETL Pipeline](#running-the-etl-pipeline)
7. [ğŸ“¸ Screenshots](#screenshots)

---

## 1. ğŸ“ Project Structure

Gaming_DW_Project/
â”‚-- raw-data/
â”‚ â”œâ”€â”€ players.csv
â”‚ â”œâ”€â”€ sessions.csv
â”‚ â”œâ”€â”€ purchases.csv
â”‚-- scripts/
â”‚ â”œâ”€â”€ etl.py
â”‚ â”œâ”€â”€ run_etl.bat
â”‚ â”œâ”€â”€ dim_date.sql
â”‚ â”œâ”€â”€ dim_player.sql
â”‚ â”œâ”€â”€ dim_game.sql
â”‚ â”œâ”€â”€ stg_sessions.sql
â”‚ â”œâ”€â”€ stg_purchases.sql
â”‚ â”œâ”€â”€ stg_players.sql
â”‚-- documentation/
â”‚ â”œâ”€â”€ project_report.pdf
â”‚ â”œâ”€â”€ data_dictionary.md
â”‚-- snapshots/
â”‚-- ER_diagram/
â”‚-- README.md

## 2. âš™ï¸ Setup Instructions

### Prerequisites

- **Google Cloud SDK** installed and authenticated
- **BigQuery enabled** in Google Cloud
- **Python 3.x** installed
- **Required Python libraries** 

### Setting Up Google Cloud Authentication

1. Download the JSON key for your Google Cloud service account.
2. Set the environment variable:
   ```sh
   set GOOGLE_APPLICATION_CREDENTIALS=C:\path\to\your\key.json
   
3. â° ETL Automation with Task Scheduler
Schedule the Task
Open Task Scheduler (taskschd.msc).
Click Create Basic Task.
Name it Gaming_ETL_Job.
Set the trigger (Daily or Hourly).
Select Start a Program as the action.
Browse and select run_etl.bat.
Finish and enable the task.

4. ğŸš€ Running the ETL Pipeline
Manual Execution
Run the ETL script manually
python etl.py

ETL Pipeline Steps
Extract: Load raw data from CSV files.
Transform: Clean data, handle missing values, and aggregate purchases.
Load: Insert data into BigQuery tables.
