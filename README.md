# ğŸ® Gaming Data Warehouse Project

## ğŸ“š Project Overview

This project implements a **Gaming Data Warehouse** to analyze player engagement, game sessions, and in-game purchases. The ETL pipeline automates data extraction, transformation, and loading into **Google BigQuery** using **Windows Task Scheduler**.

## ğŸ“‘ Table of Contents

1. [ğŸ“ Project Structure]
2. [âš™ï¸ Setup Instructions]
3. [â° ETL Automation with Task Scheduler]
4. [ğŸš€ Running the ETL Pipeline]
5. [ğŸ“Š Data Model]
6. [ğŸ“¸ Screenshots](#screenshots)

---

## 1. ğŸ“ Project Structure

GAMING_DW_PROJECT/
â”‚
â”œâ”€â”€ datasets/
â”‚ â”œâ”€â”€ csv.csv # Contains session data
â”‚ â”œâ”€â”€ players.csv # Contains player data
â”‚ â””â”€â”€ purchases.csv # Contains purchase data
â”‚
â”œâ”€â”€ documentation/
â”‚ â”œâ”€â”€ data_dictionary.md # Documentation for data fields and definitions
â”‚ â””â”€â”€ final_doc.md # Final documentation for the project
â”‚
â”œâ”€â”€ ER_diagram/
â”‚ â”œâ”€â”€ dimensional_model_schema.png # Diagram of the dimensional model
â”‚ â””â”€â”€ normalized_schema.png # Diagram of the normalized schema
â”‚
â”œâ”€â”€ etl/
â”‚ â”œâ”€â”€ etl.py # Main ETL script
â”‚ â””â”€â”€ run_etl.bat # Batch file to run the ETL process
â”‚
â”œâ”€â”€ raw-data/
â”‚ â”œâ”€â”€ game_sessions.csv # Raw session data
â”‚ â”œâ”€â”€ players.json # Raw player data in JSON format
â”‚ â””â”€â”€ purchases.xml # Raw purchase data in XML format
â”‚
â”œâ”€â”€ screenshots/ # Directory for screenshots related to the project
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ dimensional_model.sql # SQL script for creating the dimensional model
â”‚ â””â”€â”€ staging_tables.sql # SQL script for creating staging tables
â”‚
â”œâ”€â”€ LICENSE # License file for the project
â””â”€â”€ README.md # This README file

## 2. âš™ï¸ Setup Instructions

### Prerequisites

- **Google Cloud SDK** installed and authenticated.
- **BigQuery enabled** in Google Cloud.
- **Python 3.x** installed.
- **Required Python libraries** (install via pip):
  ```sh
  pip install pandas google-cloud-bigquery
  
Setting Up Google Cloud Authentication
Download the JSON key for your Google Cloud service account.
Set the environment variable:
set GOOGLE_APPLICATION_CREDENTIALS=C:\path\to\your\key.json

3. â° ETL Automation with Task Scheduler
To automate the ETL pipeline, schedule it using Windows Task Scheduler.

Schedule the Task
Open Task Scheduler (taskschd.msc).
Click Create Basic Task.
Name it Gaming_ETL_Job.
Set the trigger (Daily or Hourly).
Select Start a Program as the action.
Browse and select run_etl.bat.
Finish and enable the task.

4. ğŸš€ Running the ETL Pipeline
Manual Execution
Run the ETL script manually:
python etl.py

ETL Pipeline Steps
Extract: Load raw data from CSV files.
Transform:
Clean data, handle missing values.
Aggregate purchases per player.
Convert date columns.
Assign surrogate keys.
Load: Insert transformed data into BigQuery tables.
